Namespace(batch_size=128, dataname='DOTA', drop_rate=0.1, epochs=300, img_size=224, latent_vec_dim=128, lr=0.002, mode='test', num_classes=15, num_heads=8, num_layers=12, patch_size=16, pretrained=1, pretrained_path='models/dota.pth', save_acc=50, weight_decay=0)
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
VisionTransformer                                  [128, 15]                 --
├─LinearProjection: 1-1                            [128, 197, 128]           25,344
│    └─Linear: 2-1                                 [128, 196, 128]           98,432
│    └─Dropout: 2-2                                [128, 197, 128]           --
├─ModuleList: 1-2                                  --                        --
│    └─TFencoderLayer: 2-3                         [128, 197, 128]           --
│    │    └─LayerNorm: 3-1                         [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-2          [128, 197, 128]           49,536
│    │    └─Dropout: 3-3                           [128, 197, 128]           --
│    │    └─LayerNorm: 3-4                         [128, 197, 128]           256
│    │    └─Sequential: 3-5                        [128, 197, 128]           16,576
│    └─TFencoderLayer: 2-4                         [128, 197, 128]           --
│    │    └─LayerNorm: 3-6                         [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-7          [128, 197, 128]           49,536
│    │    └─Dropout: 3-8                           [128, 197, 128]           --
│    │    └─LayerNorm: 3-9                         [128, 197, 128]           256
│    │    └─Sequential: 3-10                       [128, 197, 128]           16,576
│    └─TFencoderLayer: 2-5                         [128, 197, 128]           --
│    │    └─LayerNorm: 3-11                        [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-12         [128, 197, 128]           49,536
│    │    └─Dropout: 3-13                          [128, 197, 128]           --
│    │    └─LayerNorm: 3-14                        [128, 197, 128]           256
│    │    └─Sequential: 3-15                       [128, 197, 128]           16,576
│    └─TFencoderLayer: 2-6                         [128, 197, 128]           --
│    │    └─LayerNorm: 3-16                        [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-17         [128, 197, 128]           49,536
│    │    └─Dropout: 3-18                          [128, 197, 128]           --
│    │    └─LayerNorm: 3-19                        [128, 197, 128]           256
│    │    └─Sequential: 3-20                       [128, 197, 128]           16,576
│    └─TFencoderLayer: 2-7                         [128, 197, 128]           --
│    │    └─LayerNorm: 3-21                        [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-22         [128, 197, 128]           49,536
│    │    └─Dropout: 3-23                          [128, 197, 128]           --
│    │    └─LayerNorm: 3-24                        [128, 197, 128]           256
│    │    └─Sequential: 3-25                       [128, 197, 128]           16,576
│    └─TFencoderLayer: 2-8                         [128, 197, 128]           --
│    │    └─LayerNorm: 3-26                        [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-27         [128, 197, 128]           49,536
│    │    └─Dropout: 3-28                          [128, 197, 128]           --
│    │    └─LayerNorm: 3-29                        [128, 197, 128]           256
│    │    └─Sequential: 3-30                       [128, 197, 128]           16,576
│    └─TFencoderLayer: 2-9                         [128, 197, 128]           --
│    │    └─LayerNorm: 3-31                        [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-32         [128, 197, 128]           49,536
│    │    └─Dropout: 3-33                          [128, 197, 128]           --
│    │    └─LayerNorm: 3-34                        [128, 197, 128]           256
│    │    └─Sequential: 3-35                       [128, 197, 128]           16,576
│    └─TFencoderLayer: 2-10                        [128, 197, 128]           --
│    │    └─LayerNorm: 3-36                        [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-37         [128, 197, 128]           49,536
│    │    └─Dropout: 3-38                          [128, 197, 128]           --
│    │    └─LayerNorm: 3-39                        [128, 197, 128]           256
│    │    └─Sequential: 3-40                       [128, 197, 128]           16,576
│    └─TFencoderLayer: 2-11                        [128, 197, 128]           --
│    │    └─LayerNorm: 3-41                        [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-42         [128, 197, 128]           49,536
│    │    └─Dropout: 3-43                          [128, 197, 128]           --
│    │    └─LayerNorm: 3-44                        [128, 197, 128]           256
│    │    └─Sequential: 3-45                       [128, 197, 128]           16,576
│    └─TFencoderLayer: 2-12                        [128, 197, 128]           --
│    │    └─LayerNorm: 3-46                        [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-47         [128, 197, 128]           49,536
│    │    └─Dropout: 3-48                          [128, 197, 128]           --
│    │    └─LayerNorm: 3-49                        [128, 197, 128]           256
│    │    └─Sequential: 3-50                       [128, 197, 128]           16,576
│    └─TFencoderLayer: 2-13                        [128, 197, 128]           --
│    │    └─LayerNorm: 3-51                        [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-52         [128, 197, 128]           49,536
│    │    └─Dropout: 3-53                          [128, 197, 128]           --
│    │    └─LayerNorm: 3-54                        [128, 197, 128]           256
│    │    └─Sequential: 3-55                       [128, 197, 128]           16,576
│    └─TFencoderLayer: 2-14                        [128, 197, 128]           --
│    │    └─LayerNorm: 3-56                        [128, 197, 128]           256
│    │    └─MultiheadedSelfAttention: 3-57         [128, 197, 128]           49,536
│    │    └─Dropout: 3-58                          [128, 197, 128]           --
│    │    └─LayerNorm: 3-59                        [128, 197, 128]           256
│    │    └─Sequential: 3-60                       [128, 197, 128]           16,576
├─Sequential: 1-3                                  [128, 15]                 --
│    └─LayerNorm: 2-15                             [128, 128]                256
│    └─Linear: 2-16                                [128, 15]                 1,935
====================================================================================================
Total params: 925,455
Trainable params: 925,455
Non-trainable params: 0
Total mult-adds (M): 115.21
====================================================================================================
Input size (MB): 77.07
Forward/backward pass size (MB): 2039.89
Params size (MB): 3.60
Estimated Total Size (MB): 2120.56
====================================================================================================
test loss: 0.760, test acc 76.15 %
